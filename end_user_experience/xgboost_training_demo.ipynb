{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "\n",
    "!pip install -U sagemaker scikit-learn pandas boto3\n",
    "!source ../.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get region, role, bucket\n",
    "\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get IRIS Data\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Prepare Data\n",
    "\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "\n",
    "iris_df = iris_df[['target'] + [col for col in iris_df.columns if col != 'target']]\n",
    "\n",
    "train_data, test_data = train_test_split(iris_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.to_csv('./data/train.csv', index=False, header=False)\n",
    "test_data.to_csv('./data/test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Upload Data\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "prefix = \"DEMO-scikit-iris\"\n",
    "TRAIN_DATA = \"train.csv\"\n",
    "TEST_DATA = \"test.csv\"\n",
    "WORK_DIRECTORY = \"data\"\n",
    "\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    WORK_DIRECTORY, bucket=bucket, key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY)\n",
    ")\n",
    "\n",
    "s3_input_path = \"s3://{}/{}/data/{}\".format(bucket, prefix, TRAIN_DATA)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "print(s3_input_path)\n",
    "print(s3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "# Fetch XGBOOST image\n",
    "\n",
    "image = image_uris.retrieve(framework='xgboost',region=region, version=\"latest\")\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrainingJob with Boto3\n",
    "\n",
    "import time\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "job_name_boto = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "response = client.create_training_job(\n",
    "    TrainingJobName=job_name_boto,\n",
    "    HyperParameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    AlgorithmSpecification={\n",
    "        'TrainingImage': image,\n",
    "        'TrainingInputMode': 'File'\n",
    "    },\n",
    "    RoleArn=role,\n",
    "    InputDataConfig=[\n",
    "        {\n",
    "            'ChannelName': 'train',\n",
    "            'ContentType': 'csv',\n",
    "            'DataSource': {\n",
    "                'S3DataSource': {\n",
    "                    'S3DataType': 'S3Prefix',\n",
    "                    'S3Uri': s3_input_path,\n",
    "                    'S3DataDistributionType': 'FullyReplicated'\n",
    "                }\n",
    "            },\n",
    "            'CompressionType': 'None',\n",
    "            'RecordWrapperType': 'None'\n",
    "        }\n",
    "    ],\n",
    "    OutputDataConfig={\n",
    "        'S3OutputPath': s3_output_path\n",
    "    },\n",
    "    ResourceConfig={\n",
    "        'InstanceType': 'ml.m4.xlarge',\n",
    "        'InstanceCount': 1,\n",
    "        'VolumeSizeInGB': 30\n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 600\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for TrainingJob witn Boto3\n",
    "import time\n",
    "while True:\n",
    "    response = client.describe_training_job(TrainingJobName=job_name_boto)\n",
    "    status = response['TrainingJobStatus']\n",
    "    if status in ['Failed', 'Completed', 'Stopped']:\n",
    "        print(status)\n",
    "        if status == 'Failed':\n",
    "            print(response['FailureReason'])\n",
    "        break\n",
    "    print(\"-\", end=\" \")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrainingJob V3\n",
    "\n",
    "import time\n",
    "from src.generated.resources import TrainingJob, AlgorithmSpecification, Channel, DataSource, S3DataSource, OutputDataConfig, ResourceConfig, StoppingCondition\n",
    "\n",
    "job_name_v3 = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "training_job = TrainingJob.create(\n",
    "    training_job_name=job_name_v3,\n",
    "    hyper_parameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    algorithm_specification=AlgorithmSpecification(\n",
    "        training_image=image,\n",
    "        training_input_mode='File'\n",
    "    ),\n",
    "    role_arn=role,\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name='train',\n",
    "            content_type='csv',\n",
    "            compression_type='None',\n",
    "            record_wrapper_type='None',\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type='S3Prefix',\n",
    "                    s3_uri=s3_input_path,\n",
    "                    s3_data_distribution_type='FullyReplicated'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=s3_output_path\n",
    "    ),\n",
    "    resource_config=ResourceConfig(\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        instance_count=1,\n",
    "        volume_size_in_g_b=30\n",
    "    ),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=600\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for TrainingJob V3\n",
    "from src.generated.resources import TrainingJob\n",
    "\n",
    "training_job = TrainingJob.get(training_job_name = job_name_v3)\n",
    "training_job.wait()\n",
    "\n",
    "if training_job.training_job_status == \"Failed\":\n",
    "    print(training_job.failure_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List TrainingJobs V3\n",
    "import datetime \n",
    "from src.generated.resources import TrainingJob\n",
    "\n",
    "creation_time_after = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "\n",
    "for job in TrainingJob.get_all(creation_time_after=creation_time_after):\n",
    "    print(job.training_job_name, job.training_job_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from src.generated.shapes import ClusterInstanceGroupSpecification, ClusterLifeCycleConfig\n",
    "# Creating TrainingJob using some inputs from Config File - Intelligent Defaults\n",
    "\n",
    "import os\n",
    "import time\n",
    "from src.generated.resources import TrainingJob, AlgorithmSpecification, Channel, DataSource, S3DataSource, OutputDataConfig, ResourceConfig, StoppingCondition, Cluster\n",
    "\n",
    "# Setting path of Config file in environment variable \n",
    "os.environ['SAGEMAKER_ADMIN_CONFIG_OVERRIDE'] = '/Users/nargokul/workspace/sagemaker-code-gen/sample/sagemaker/2017-07-24/default-configs.json'\n",
    "\n",
    "# Generating names for resources\n",
    "job_name_v3 = 'xgboost-iris-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "cluster_name_v3 = 'xgboost-cluster-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "\n",
    "# This will create a Cluster - one that does not have default configs in the default-configs.json and will use values from Global Defaults\n",
    "cluster = Cluster.create(\n",
    "    cluster_name=cluster_name_v3,\n",
    "    instance_groups=[ClusterInstanceGroupSpecification(instance_count=1, instance_group_name=\"instance-group-11\", instance_type=\"ml.m5.4xlarge\", life_cycle_config=ClusterLifeCycleConfig(source_s3_uri=s3_input_path, on_create=\"dothis\"),execution_role=role )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This will create a Training Job using specific VPC Config present in the default configs JSON\n",
    "training_job = TrainingJob.create(\n",
    "    training_job_name=job_name_v3,\n",
    "    hyper_parameters={\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': '3',\n",
    "        'num_round': '10',\n",
    "        'eval_metric': 'merror'\n",
    "    },\n",
    "    algorithm_specification=AlgorithmSpecification(\n",
    "        training_image=image,\n",
    "        training_input_mode='File'\n",
    "    ),\n",
    "    role_arn=role,\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name='train',\n",
    "            content_type='csv',\n",
    "            compression_type='None',\n",
    "            record_wrapper_type='None',\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type='S3Prefix',\n",
    "                    s3_uri=s3_input_path,\n",
    "                    s3_data_distribution_type='FullyReplicated'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    output_data_config=OutputDataConfig(\n",
    "        s3_output_path=s3_output_path\n",
    "    ),\n",
    "    resource_config=ResourceConfig(\n",
    "        instance_type='ml.m4.xlarge',\n",
    "        instance_count=1,\n",
    "        volume_size_in_g_b=30\n",
    "    ),\n",
    "    stopping_condition=StoppingCondition(\n",
    "        max_runtime_in_seconds=600\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
